// Code generated by github.com/kjkrol/goke/internal/cmd/gen/views; DO NOT EDIT.
package goke

import (
	"fmt"
	"github.com/kjkrol/goke/internal/core"
	"iter"
	"reflect"
	"unsafe"
)

// --------------- View1 ---------------

// View1 provides a type-safe iterator and access layer for entities that
// possess exactly 1 specific stateful components. It acts as a specialized
// window into the ECS world, filtering archetypes that satisfy the required
// component mask and any additional constraints defined via BlueprintOptions.
//
// By leveraging pre-calculated component offsets, View1 enables
// O(1) access to component data during iteration, making it the primary
// tool for implementing high-performance systems and logic loops.
type View1[T1 any] struct {
	*core.View
}

// NewView1 initializes a query for exactly 1 components.
// It panics if the component registration fails, if there are duplicate
// components, or if options (like Exclude) create a logical contradiction.
//
// This ensures that the View is valid and ready for high-performance
// iteration immediately after creation.
func NewView1[T1 any](ecs *ECS, opts ...BlueprintOption) *View1[T1] {
	registry := ecs.registry
	blueprint := core.NewBlueprint(registry)
	componentsRegistry := &registry.ComponentsRegistry

	// Helper: Validates that the required component can be part of the view.
	mustAdd := func(info core.ComponentInfo) {
		if err := blueprint.WithComp(info); err != nil {
			panic(fmt.Sprintf("goke: view1 init failed: %v", err))
		}
	}

	// 1. Resolve Component Infos (Type -> ID)

	info1 := componentsRegistry.GetOrRegister(reflect.TypeFor[T1]())

	// 2. Add to Blueprint (Build Mask)

	mustAdd(info1)

	// 3. Apply dynamic options (Include/Exclude)
	for _, opt := range opts {
		if err := opt(blueprint); err != nil {
			panic(fmt.Sprintf("goke: view1 option failed: %v", err))
		}
	}

	// 4. Define Rigid Layout (Slice Literal - Zero Allocation Overhead)
	// This guarantees that T1 is at index 0, T2 at index 1, etc.
	layout := []core.ComponentInfo{
		info1,
	}

	view := core.NewView(blueprint, layout, registry)
	return &View1[T1]{View: view}
}

// All returns an iterator (iter.Seq2) that yields the unique Entity identifier
// and a tuple of pointers to its 1 components. This is designed for use
// in range loops, providing a clean, idiomatic Go way to process data while
// maintaining maximum cache efficiency.
//
// The iteration is performed archetype by archetype, ensuring that data is
// accessed contiguously in memory, which significantly reduces CPU cache misses.
//
// Example usage:
//
//	for head, _ := range view1.All() {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	}
func (v *View1[T1]) All() iter.Seq2[
	struct {
		Entity core.Entity
		V1     *T1
	},
	struct{},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
		},
		struct{},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))

		// Loop over matched archetypes - Value Copy is fast enough (stack allocation)
		for _, ma := range v.Baked {
			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// Accessing fields on stack-allocated 'ma' is blazing fast
			offsetEntity := ma.EntityChunkOffset
			offset1 := ma.FieldsOffsets[0]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk (Pure Math)
				base := chunk.Ptr
				ptrEntity := unsafe.Add(base, offsetEntity)
				ptr1 := unsafe.Add(base, offset1)

				// 5. Hot Loop (Death Loop)
				for count > 0 {
					// Construct Head
					head := struct {
						Entity core.Entity
						V1     *T1
					}{
						Entity: *(*core.Entity)(ptrEntity),
						V1:     (*T1)(ptr1),
					}

					// Construct Tail (if exists)

					tail := struct{}{}

					// Yield execution to the user
					if !yield(head, tail) {
						return
					}

					// 6. Pointer Arithmetic (Move to next row)
					ptrEntity = unsafe.Add(ptrEntity, core.EntitySize)
					ptr1 = unsafe.Add(ptr1, stride1)

					count--
				}
			}
		}
	}
}

// Filter returns an iterator (iter.Seq2) that yields only the entities
// specified in the selected slice, provided they match the View's archetype
// constraints. It is optimized for scenarios where a subset of entities
// is pre-determined (e.g., via spatial partitioning or sorted results)
// but requires high-speed access to their component data.
//
// The iterator performs an internal validation for each entity to ensure
// it still belongs to an archetype compatible with this View, preventing
// invalid memory access if the entity's composition has changed.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, _ := range view1.Filter(selected) {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	}
func (v *View1[T1]) Filter(selected []Entity) iter.Seq2[
	struct {
		Entity Entity
		V1     *T1
	},
	struct{},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
		},
		struct{},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Column descriptor cache
		var col1 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Change Detection (Cache descriptors)
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache all column descriptors for this archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)

				lastArchID = link.ArchId
			}

			if currentArch == nil {
				continue
			}

			// 2. Resolve Chunk
			// Access the physical page using the index from the link
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			head := struct {
				Entity core.Entity
				V1     *T1
			}{
				Entity: e,
				V1:     (*T1)(col1.GetPointer(chunk, link.ChunkRow)),
			}

			// 4. Construct Result (Tail)

			tail := struct{}{}

			if !yield(head, tail) {
				return
			}
		}
	}
}

// Values returns a performance-critical iterator (iter.Seq2) that yields only
// component pointers, grouped into anonymous head and tail structures.
// This method is specifically designed for high-throughput data processing
// where the Entity identifier is not required.
//
// By omitting the Entity ID, this method minimizes stack pressure and
// register usage, focusing purely on data-driven transformation.
//
// Example usage:
//
//	for head, _ := range view1.Values() {
//	    v1 := head.V1
//
//
//	}
func (v *View1[T1]) Values() iter.Seq2[
	struct{ V1 *T1 },
	struct{},
] {
	return func(yield func(
		struct{ V1 *T1 },
		struct{},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))

		// Loop over matched archetypes
		for _, ma := range v.Baked {

			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// We use the same lookup array as in All(), just skipping the Entity offset.
			offset1 := ma.FieldsOffsets[0]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk
				// Pure math: ChunkBase + ComponentOffset
				base := chunk.Ptr
				ptr1 := unsafe.Add(base, offset1)

				// 5. Hot Loop (Death Loop)
				for count > 0 {

					// Construct Head
					head := struct{ V1 *T1 }{V1: (*T1)(ptr1)}

					// Construct Tail

					tail := struct{}{}

					if !yield(head, tail) {
						return
					}

					// 6. Increment Pointers (Pointer Arithmetic)
					ptr1 = unsafe.Add(ptr1, stride1)

					count--
				}
			}
		}
	}
}

// FilterValues returns an iterator (iter.Seq2) that yields component pointers
// for a pre-selected subset of entities, skipping the Entity identifier.
// It is optimized for cases where the entity list is already known (e.g., from spatial partitioning).
//
// Like the Values method, it uses anonymous structures to ensure the Go compiler
// can perform aggressive register allocation by avoiding Entity ID overhead.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, _ := range view1.FilterValues(selected) {
//	    v1 := head.V1
//
//
//	}
func (v *View1[T1]) FilterValues(selected []core.Entity) iter.Seq2[
	struct{ V1 *T1 },
	struct{},
] {
	return func(yield func(
		struct{ V1 *T1 },
		struct{},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Cache for column descriptors to avoid repeated map lookups
		var col1 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Transition Detection
			// We only refresh column descriptors when the archetype changes.
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				// Verify if the archetype matches the view's mask requirements
				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache column accessors for this specific archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)

				lastArchID = link.ArchId
			}

			// If currentArch is nil, it means the current entity's archetype doesn't match the view
			if currentArch == nil {
				continue
			}

			// 2. Resolve Physical Chunk
			// Access the memory page (Chunk) using the index from the link store.
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			vhead := struct{ V1 *T1 }{V1: (*T1)(col1.GetPointer(chunk, link.ChunkRow))}

			// 4. Construct Result (Tail)

			vtail := struct{}{}

			if !yield(vhead, vtail) {
				return
			}
		}
	}
}

// --------------- View2 ---------------

// View2 provides a type-safe iterator and access layer for entities that
// possess exactly 2 specific stateful components. It acts as a specialized
// window into the ECS world, filtering archetypes that satisfy the required
// component mask and any additional constraints defined via BlueprintOptions.
//
// By leveraging pre-calculated component offsets, View2 enables
// O(1) access to component data during iteration, making it the primary
// tool for implementing high-performance systems and logic loops.
type View2[T1, T2 any] struct {
	*core.View
}

// NewView2 initializes a query for exactly 2 components.
// It panics if the component registration fails, if there are duplicate
// components, or if options (like Exclude) create a logical contradiction.
//
// This ensures that the View is valid and ready for high-performance
// iteration immediately after creation.
func NewView2[T1, T2 any](ecs *ECS, opts ...BlueprintOption) *View2[T1, T2] {
	registry := ecs.registry
	blueprint := core.NewBlueprint(registry)
	componentsRegistry := &registry.ComponentsRegistry

	// Helper: Validates that the required component can be part of the view.
	mustAdd := func(info core.ComponentInfo) {
		if err := blueprint.WithComp(info); err != nil {
			panic(fmt.Sprintf("goke: view2 init failed: %v", err))
		}
	}

	// 1. Resolve Component Infos (Type -> ID)

	info1 := componentsRegistry.GetOrRegister(reflect.TypeFor[T1]())

	info2 := componentsRegistry.GetOrRegister(reflect.TypeFor[T2]())

	// 2. Add to Blueprint (Build Mask)

	mustAdd(info1)

	mustAdd(info2)

	// 3. Apply dynamic options (Include/Exclude)
	for _, opt := range opts {
		if err := opt(blueprint); err != nil {
			panic(fmt.Sprintf("goke: view2 option failed: %v", err))
		}
	}

	// 4. Define Rigid Layout (Slice Literal - Zero Allocation Overhead)
	// This guarantees that T1 is at index 0, T2 at index 1, etc.
	layout := []core.ComponentInfo{
		info1, info2,
	}

	view := core.NewView(blueprint, layout, registry)
	return &View2[T1, T2]{View: view}
}

// All returns an iterator (iter.Seq2) that yields the unique Entity identifier
// and a tuple of pointers to its 2 components. This is designed for use
// in range loops, providing a clean, idiomatic Go way to process data while
// maintaining maximum cache efficiency.
//
// The iteration is performed archetype by archetype, ensuring that data is
// accessed contiguously in memory, which significantly reduces CPU cache misses.
//
// Example usage:
//
//	for head, _ := range view2.All() {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	    v2 := head.V2
//
//	}
func (v *View2[T1, T2]) All() iter.Seq2[
	struct {
		Entity core.Entity
		V1     *T1
		V2     *T2
	},
	struct{},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
		},
		struct{},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))

		// Loop over matched archetypes - Value Copy is fast enough (stack allocation)
		for _, ma := range v.Baked {
			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// Accessing fields on stack-allocated 'ma' is blazing fast
			offsetEntity := ma.EntityChunkOffset
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk (Pure Math)
				base := chunk.Ptr
				ptrEntity := unsafe.Add(base, offsetEntity)
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)

				// 5. Hot Loop (Death Loop)
				for count > 0 {
					// Construct Head
					head := struct {
						Entity core.Entity
						V1     *T1
						V2     *T2
					}{
						Entity: *(*core.Entity)(ptrEntity),
						V1:     (*T1)(ptr1),
						V2:     (*T2)(ptr2),
					}

					// Construct Tail (if exists)

					tail := struct{}{}

					// Yield execution to the user
					if !yield(head, tail) {
						return
					}

					// 6. Pointer Arithmetic (Move to next row)
					ptrEntity = unsafe.Add(ptrEntity, core.EntitySize)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)

					count--
				}
			}
		}
	}
}

// Filter returns an iterator (iter.Seq2) that yields only the entities
// specified in the selected slice, provided they match the View's archetype
// constraints. It is optimized for scenarios where a subset of entities
// is pre-determined (e.g., via spatial partitioning or sorted results)
// but requires high-speed access to their component data.
//
// The iterator performs an internal validation for each entity to ensure
// it still belongs to an archetype compatible with this View, preventing
// invalid memory access if the entity's composition has changed.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, _ := range view2.Filter(selected) {
//	    entity := head.Entity
//	    v1 := head.V1
//
//
//	    v2 := head.V2
//
//
//	}
func (v *View2[T1, T2]) Filter(selected []Entity) iter.Seq2[
	struct {
		Entity Entity
		V1     *T1
		V2     *T2
	},
	struct{},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
		},
		struct{},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Column descriptor cache
		var col1 *core.Column
		var col2 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Change Detection (Cache descriptors)
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache all column descriptors for this archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)

				lastArchID = link.ArchId
			}

			if currentArch == nil {
				continue
			}

			// 2. Resolve Chunk
			// Access the physical page using the index from the link
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			head := struct {
				Entity core.Entity
				V1     *T1
				V2     *T2
			}{
				Entity: e,
				V1:     (*T1)(col1.GetPointer(chunk, link.ChunkRow)),
				V2:     (*T2)(col2.GetPointer(chunk, link.ChunkRow)),
			}

			// 4. Construct Result (Tail)

			tail := struct{}{}

			if !yield(head, tail) {
				return
			}
		}
	}
}

// Values returns a performance-critical iterator (iter.Seq2) that yields only
// component pointers, grouped into anonymous head and tail structures.
// This method is specifically designed for high-throughput data processing
// where the Entity identifier is not required.
//
// By omitting the Entity ID, this method minimizes stack pressure and
// register usage, focusing purely on data-driven transformation.
//
// Example usage:
//
//	for head, _ := range view2.Values() {
//	    v1 := head.V1
//
//	    v2 := head.V2
//
//	}
func (v *View2[T1, T2]) Values() iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
	},
	struct{},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
		},
		struct{},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))

		// Loop over matched archetypes
		for _, ma := range v.Baked {

			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// We use the same lookup array as in All(), just skipping the Entity offset.
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk
				// Pure math: ChunkBase + ComponentOffset
				base := chunk.Ptr
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)

				// 5. Hot Loop (Death Loop)
				for count > 0 {

					// Construct Head
					head := struct {
						V1 *T1
						V2 *T2
					}{V1: (*T1)(ptr1), V2: (*T2)(ptr2)}

					// Construct Tail

					tail := struct{}{}

					if !yield(head, tail) {
						return
					}

					// 6. Increment Pointers (Pointer Arithmetic)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)

					count--
				}
			}
		}
	}
}

// FilterValues returns an iterator (iter.Seq2) that yields component pointers
// for a pre-selected subset of entities, skipping the Entity identifier.
// It is optimized for cases where the entity list is already known (e.g., from spatial partitioning).
//
// Like the Values method, it uses anonymous structures to ensure the Go compiler
// can perform aggressive register allocation by avoiding Entity ID overhead.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, _ := range view2.FilterValues(selected) {
//	    v1 := head.V1
//
//	    v2 := head.V2
//
//	}
func (v *View2[T1, T2]) FilterValues(selected []core.Entity) iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
	},
	struct{},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
		},
		struct{},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Cache for column descriptors to avoid repeated map lookups
		var col1 *core.Column
		var col2 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Transition Detection
			// We only refresh column descriptors when the archetype changes.
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				// Verify if the archetype matches the view's mask requirements
				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache column accessors for this specific archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)

				lastArchID = link.ArchId
			}

			// If currentArch is nil, it means the current entity's archetype doesn't match the view
			if currentArch == nil {
				continue
			}

			// 2. Resolve Physical Chunk
			// Access the memory page (Chunk) using the index from the link store.
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			vhead := struct {
				V1 *T1
				V2 *T2
			}{V1: (*T1)(col1.GetPointer(chunk, link.ChunkRow)), V2: (*T2)(col2.GetPointer(chunk, link.ChunkRow))}

			// 4. Construct Result (Tail)

			vtail := struct{}{}

			if !yield(vhead, vtail) {
				return
			}
		}
	}
}

// --------------- View3 ---------------

// View3 provides a type-safe iterator and access layer for entities that
// possess exactly 3 specific stateful components. It acts as a specialized
// window into the ECS world, filtering archetypes that satisfy the required
// component mask and any additional constraints defined via BlueprintOptions.
//
// By leveraging pre-calculated component offsets, View3 enables
// O(1) access to component data during iteration, making it the primary
// tool for implementing high-performance systems and logic loops.
type View3[T1, T2, T3 any] struct {
	*core.View
}

// NewView3 initializes a query for exactly 3 components.
// It panics if the component registration fails, if there are duplicate
// components, or if options (like Exclude) create a logical contradiction.
//
// This ensures that the View is valid and ready for high-performance
// iteration immediately after creation.
func NewView3[T1, T2, T3 any](ecs *ECS, opts ...BlueprintOption) *View3[T1, T2, T3] {
	registry := ecs.registry
	blueprint := core.NewBlueprint(registry)
	componentsRegistry := &registry.ComponentsRegistry

	// Helper: Validates that the required component can be part of the view.
	mustAdd := func(info core.ComponentInfo) {
		if err := blueprint.WithComp(info); err != nil {
			panic(fmt.Sprintf("goke: view3 init failed: %v", err))
		}
	}

	// 1. Resolve Component Infos (Type -> ID)

	info1 := componentsRegistry.GetOrRegister(reflect.TypeFor[T1]())

	info2 := componentsRegistry.GetOrRegister(reflect.TypeFor[T2]())

	info3 := componentsRegistry.GetOrRegister(reflect.TypeFor[T3]())

	// 2. Add to Blueprint (Build Mask)

	mustAdd(info1)

	mustAdd(info2)

	mustAdd(info3)

	// 3. Apply dynamic options (Include/Exclude)
	for _, opt := range opts {
		if err := opt(blueprint); err != nil {
			panic(fmt.Sprintf("goke: view3 option failed: %v", err))
		}
	}

	// 4. Define Rigid Layout (Slice Literal - Zero Allocation Overhead)
	// This guarantees that T1 is at index 0, T2 at index 1, etc.
	layout := []core.ComponentInfo{
		info1, info2, info3,
	}

	view := core.NewView(blueprint, layout, registry)
	return &View3[T1, T2, T3]{View: view}
}

// All returns an iterator (iter.Seq2) that yields the unique Entity identifier
// and a tuple of pointers to its 3 components. This is designed for use
// in range loops, providing a clean, idiomatic Go way to process data while
// maintaining maximum cache efficiency.
//
// The iteration is performed archetype by archetype, ensuring that data is
// accessed contiguously in memory, which significantly reduces CPU cache misses.
//
// Example usage:
//
//	for head, _ := range view3.All() {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	    v3 := head.V3
//
//	}
func (v *View3[T1, T2, T3]) All() iter.Seq2[
	struct {
		Entity core.Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct{},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct{},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))

		// Loop over matched archetypes - Value Copy is fast enough (stack allocation)
		for _, ma := range v.Baked {
			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// Accessing fields on stack-allocated 'ma' is blazing fast
			offsetEntity := ma.EntityChunkOffset
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk (Pure Math)
				base := chunk.Ptr
				ptrEntity := unsafe.Add(base, offsetEntity)
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)

				// 5. Hot Loop (Death Loop)
				for count > 0 {
					// Construct Head
					head := struct {
						Entity core.Entity
						V1     *T1
						V2     *T2
						V3     *T3
					}{
						Entity: *(*core.Entity)(ptrEntity),
						V1:     (*T1)(ptr1),
						V2:     (*T2)(ptr2),
						V3:     (*T3)(ptr3),
					}

					// Construct Tail (if exists)

					tail := struct{}{}

					// Yield execution to the user
					if !yield(head, tail) {
						return
					}

					// 6. Pointer Arithmetic (Move to next row)
					ptrEntity = unsafe.Add(ptrEntity, core.EntitySize)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)

					count--
				}
			}
		}
	}
}

// Filter returns an iterator (iter.Seq2) that yields only the entities
// specified in the selected slice, provided they match the View's archetype
// constraints. It is optimized for scenarios where a subset of entities
// is pre-determined (e.g., via spatial partitioning or sorted results)
// but requires high-speed access to their component data.
//
// The iterator performs an internal validation for each entity to ensure
// it still belongs to an archetype compatible with this View, preventing
// invalid memory access if the entity's composition has changed.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, _ := range view3.Filter(selected) {
//	    entity := head.Entity
//	    v1 := head.V1
//
//
//	    v3 := head.V3
//
//
//	}
func (v *View3[T1, T2, T3]) Filter(selected []Entity) iter.Seq2[
	struct {
		Entity Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct{},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct{},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Column descriptor cache
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Change Detection (Cache descriptors)
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache all column descriptors for this archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)

				lastArchID = link.ArchId
			}

			if currentArch == nil {
				continue
			}

			// 2. Resolve Chunk
			// Access the physical page using the index from the link
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			head := struct {
				Entity core.Entity
				V1     *T1
				V2     *T2
				V3     *T3
			}{
				Entity: e,
				V1:     (*T1)(col1.GetPointer(chunk, link.ChunkRow)),
				V2:     (*T2)(col2.GetPointer(chunk, link.ChunkRow)),
				V3:     (*T3)(col3.GetPointer(chunk, link.ChunkRow)),
			}

			// 4. Construct Result (Tail)

			tail := struct{}{}

			if !yield(head, tail) {
				return
			}
		}
	}
}

// Values returns a performance-critical iterator (iter.Seq2) that yields only
// component pointers, grouped into anonymous head and tail structures.
// This method is specifically designed for high-throughput data processing
// where the Entity identifier is not required.
//
// By omitting the Entity ID, this method minimizes stack pressure and
// register usage, focusing purely on data-driven transformation.
//
// Example usage:
//
//	for head, _ := range view3.Values() {
//	    v1 := head.V1
//
//	    v3 := head.V3
//
//	}
func (v *View3[T1, T2, T3]) Values() iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
	},
	struct{},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
		},
		struct{},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))

		// Loop over matched archetypes
		for _, ma := range v.Baked {

			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// We use the same lookup array as in All(), just skipping the Entity offset.
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk
				// Pure math: ChunkBase + ComponentOffset
				base := chunk.Ptr
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)

				// 5. Hot Loop (Death Loop)
				for count > 0 {

					// Construct Head
					head := struct {
						V1 *T1
						V2 *T2
						V3 *T3
					}{V1: (*T1)(ptr1), V2: (*T2)(ptr2), V3: (*T3)(ptr3)}

					// Construct Tail

					tail := struct{}{}

					if !yield(head, tail) {
						return
					}

					// 6. Increment Pointers (Pointer Arithmetic)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)

					count--
				}
			}
		}
	}
}

// FilterValues returns an iterator (iter.Seq2) that yields component pointers
// for a pre-selected subset of entities, skipping the Entity identifier.
// It is optimized for cases where the entity list is already known (e.g., from spatial partitioning).
//
// Like the Values method, it uses anonymous structures to ensure the Go compiler
// can perform aggressive register allocation by avoiding Entity ID overhead.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, _ := range view3.FilterValues(selected) {
//	    v1 := head.V1
//
//	    v3 := head.V3
//
//	}
func (v *View3[T1, T2, T3]) FilterValues(selected []core.Entity) iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
	},
	struct{},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
		},
		struct{},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Cache for column descriptors to avoid repeated map lookups
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Transition Detection
			// We only refresh column descriptors when the archetype changes.
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				// Verify if the archetype matches the view's mask requirements
				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache column accessors for this specific archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)

				lastArchID = link.ArchId
			}

			// If currentArch is nil, it means the current entity's archetype doesn't match the view
			if currentArch == nil {
				continue
			}

			// 2. Resolve Physical Chunk
			// Access the memory page (Chunk) using the index from the link store.
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			vhead := struct {
				V1 *T1
				V2 *T2
				V3 *T3
			}{V1: (*T1)(col1.GetPointer(chunk, link.ChunkRow)), V2: (*T2)(col2.GetPointer(chunk, link.ChunkRow)), V3: (*T3)(col3.GetPointer(chunk, link.ChunkRow))}

			// 4. Construct Result (Tail)

			vtail := struct{}{}

			if !yield(vhead, vtail) {
				return
			}
		}
	}
}

// --------------- View4 ---------------

// View4 provides a type-safe iterator and access layer for entities that
// possess exactly 4 specific stateful components. It acts as a specialized
// window into the ECS world, filtering archetypes that satisfy the required
// component mask and any additional constraints defined via BlueprintOptions.
//
// By leveraging pre-calculated component offsets, View4 enables
// O(1) access to component data during iteration, making it the primary
// tool for implementing high-performance systems and logic loops.
type View4[T1, T2, T3, T4 any] struct {
	*core.View
}

// NewView4 initializes a query for exactly 4 components.
// It panics if the component registration fails, if there are duplicate
// components, or if options (like Exclude) create a logical contradiction.
//
// This ensures that the View is valid and ready for high-performance
// iteration immediately after creation.
func NewView4[T1, T2, T3, T4 any](ecs *ECS, opts ...BlueprintOption) *View4[T1, T2, T3, T4] {
	registry := ecs.registry
	blueprint := core.NewBlueprint(registry)
	componentsRegistry := &registry.ComponentsRegistry

	// Helper: Validates that the required component can be part of the view.
	mustAdd := func(info core.ComponentInfo) {
		if err := blueprint.WithComp(info); err != nil {
			panic(fmt.Sprintf("goke: view4 init failed: %v", err))
		}
	}

	// 1. Resolve Component Infos (Type -> ID)

	info1 := componentsRegistry.GetOrRegister(reflect.TypeFor[T1]())

	info2 := componentsRegistry.GetOrRegister(reflect.TypeFor[T2]())

	info3 := componentsRegistry.GetOrRegister(reflect.TypeFor[T3]())

	info4 := componentsRegistry.GetOrRegister(reflect.TypeFor[T4]())

	// 2. Add to Blueprint (Build Mask)

	mustAdd(info1)

	mustAdd(info2)

	mustAdd(info3)

	mustAdd(info4)

	// 3. Apply dynamic options (Include/Exclude)
	for _, opt := range opts {
		if err := opt(blueprint); err != nil {
			panic(fmt.Sprintf("goke: view4 option failed: %v", err))
		}
	}

	// 4. Define Rigid Layout (Slice Literal - Zero Allocation Overhead)
	// This guarantees that T1 is at index 0, T2 at index 1, etc.
	layout := []core.ComponentInfo{
		info1, info2, info3, info4,
	}

	view := core.NewView(blueprint, layout, registry)
	return &View4[T1, T2, T3, T4]{View: view}
}

// All returns an iterator (iter.Seq2) that yields the unique Entity identifier
// and a tuple of pointers to its 4 components. This is designed for use
// in range loops, providing a clean, idiomatic Go way to process data while
// maintaining maximum cache efficiency.
//
// The iteration is performed archetype by archetype, ensuring that data is
// accessed contiguously in memory, which significantly reduces CPU cache misses.
//
// Example usage:
//
//	for head, tail := range view4.All() {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	    v4 := tail.V4
//
//	}
func (v *View4[T1, T2, T3, T4]) All() iter.Seq2[
	struct {
		Entity core.Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct{ V4 *T4 },
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct{ V4 *T4 },
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))

		// Loop over matched archetypes - Value Copy is fast enough (stack allocation)
		for _, ma := range v.Baked {
			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// Accessing fields on stack-allocated 'ma' is blazing fast
			offsetEntity := ma.EntityChunkOffset
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk (Pure Math)
				base := chunk.Ptr
				ptrEntity := unsafe.Add(base, offsetEntity)
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)

				// 5. Hot Loop (Death Loop)
				for count > 0 {
					// Construct Head
					head := struct {
						Entity core.Entity
						V1     *T1
						V2     *T2
						V3     *T3
					}{
						Entity: *(*core.Entity)(ptrEntity),
						V1:     (*T1)(ptr1),
						V2:     (*T2)(ptr2),
						V3:     (*T3)(ptr3),
					}

					// Construct Tail (if exists)

					tail := struct{ V4 *T4 }{
						V4: (*T4)(ptr4),
					}

					// Yield execution to the user
					if !yield(head, tail) {
						return
					}

					// 6. Pointer Arithmetic (Move to next row)
					ptrEntity = unsafe.Add(ptrEntity, core.EntitySize)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)

					count--
				}
			}
		}
	}
}

// Filter returns an iterator (iter.Seq2) that yields only the entities
// specified in the selected slice, provided they match the View's archetype
// constraints. It is optimized for scenarios where a subset of entities
// is pre-determined (e.g., via spatial partitioning or sorted results)
// but requires high-speed access to their component data.
//
// The iterator performs an internal validation for each entity to ensure
// it still belongs to an archetype compatible with this View, preventing
// invalid memory access if the entity's composition has changed.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view4.Filter(selected) {
//	    entity := head.Entity
//	    v1 := head.V1
//
//
//	    v4 := tail.V4
//
//
//	}
func (v *View4[T1, T2, T3, T4]) Filter(selected []Entity) iter.Seq2[
	struct {
		Entity Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct{ V4 *T4 },
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct{ V4 *T4 },
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Column descriptor cache
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Change Detection (Cache descriptors)
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache all column descriptors for this archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)

				lastArchID = link.ArchId
			}

			if currentArch == nil {
				continue
			}

			// 2. Resolve Chunk
			// Access the physical page using the index from the link
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			head := struct {
				Entity core.Entity
				V1     *T1
				V2     *T2
				V3     *T3
			}{
				Entity: e,
				V1:     (*T1)(col1.GetPointer(chunk, link.ChunkRow)),
				V2:     (*T2)(col2.GetPointer(chunk, link.ChunkRow)),
				V3:     (*T3)(col3.GetPointer(chunk, link.ChunkRow)),
			}

			// 4. Construct Result (Tail)

			tail := struct{ V4 *T4 }{
				V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow)),
			}

			if !yield(head, tail) {
				return
			}
		}
	}
}

// Values returns a performance-critical iterator (iter.Seq2) that yields only
// component pointers, grouped into anonymous head and tail structures.
// This method is specifically designed for high-throughput data processing
// where the Entity identifier is not required.
//
// By omitting the Entity ID, this method minimizes stack pressure and
// register usage, focusing purely on data-driven transformation.
//
// Example usage:
//
//	for head, _ := range view4.Values() {
//	    v1 := head.V1
//
//	    v4 := head.V4
//
//	}
func (v *View4[T1, T2, T3, T4]) Values() iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct{},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct{},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))

		// Loop over matched archetypes
		for _, ma := range v.Baked {

			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// We use the same lookup array as in All(), just skipping the Entity offset.
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk
				// Pure math: ChunkBase + ComponentOffset
				base := chunk.Ptr
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)

				// 5. Hot Loop (Death Loop)
				for count > 0 {

					// Construct Head
					head := struct {
						V1 *T1
						V2 *T2
						V3 *T3
						V4 *T4
					}{V1: (*T1)(ptr1), V2: (*T2)(ptr2), V3: (*T3)(ptr3), V4: (*T4)(ptr4)}

					// Construct Tail

					tail := struct{}{}

					if !yield(head, tail) {
						return
					}

					// 6. Increment Pointers (Pointer Arithmetic)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)

					count--
				}
			}
		}
	}
}

// FilterValues returns an iterator (iter.Seq2) that yields component pointers
// for a pre-selected subset of entities, skipping the Entity identifier.
// It is optimized for cases where the entity list is already known (e.g., from spatial partitioning).
//
// Like the Values method, it uses anonymous structures to ensure the Go compiler
// can perform aggressive register allocation by avoiding Entity ID overhead.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, _ := range view4.FilterValues(selected) {
//	    v1 := head.V1
//
//	    v4 := head.V4
//
//	}
func (v *View4[T1, T2, T3, T4]) FilterValues(selected []core.Entity) iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct{},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct{},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Cache for column descriptors to avoid repeated map lookups
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Transition Detection
			// We only refresh column descriptors when the archetype changes.
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				// Verify if the archetype matches the view's mask requirements
				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache column accessors for this specific archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)

				lastArchID = link.ArchId
			}

			// If currentArch is nil, it means the current entity's archetype doesn't match the view
			if currentArch == nil {
				continue
			}

			// 2. Resolve Physical Chunk
			// Access the memory page (Chunk) using the index from the link store.
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			vhead := struct {
				V1 *T1
				V2 *T2
				V3 *T3
				V4 *T4
			}{V1: (*T1)(col1.GetPointer(chunk, link.ChunkRow)), V2: (*T2)(col2.GetPointer(chunk, link.ChunkRow)), V3: (*T3)(col3.GetPointer(chunk, link.ChunkRow)), V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow))}

			// 4. Construct Result (Tail)

			vtail := struct{}{}

			if !yield(vhead, vtail) {
				return
			}
		}
	}
}

// --------------- View5 ---------------

// View5 provides a type-safe iterator and access layer for entities that
// possess exactly 5 specific stateful components. It acts as a specialized
// window into the ECS world, filtering archetypes that satisfy the required
// component mask and any additional constraints defined via BlueprintOptions.
//
// By leveraging pre-calculated component offsets, View5 enables
// O(1) access to component data during iteration, making it the primary
// tool for implementing high-performance systems and logic loops.
type View5[T1, T2, T3, T4, T5 any] struct {
	*core.View
}

// NewView5 initializes a query for exactly 5 components.
// It panics if the component registration fails, if there are duplicate
// components, or if options (like Exclude) create a logical contradiction.
//
// This ensures that the View is valid and ready for high-performance
// iteration immediately after creation.
func NewView5[T1, T2, T3, T4, T5 any](ecs *ECS, opts ...BlueprintOption) *View5[T1, T2, T3, T4, T5] {
	registry := ecs.registry
	blueprint := core.NewBlueprint(registry)
	componentsRegistry := &registry.ComponentsRegistry

	// Helper: Validates that the required component can be part of the view.
	mustAdd := func(info core.ComponentInfo) {
		if err := blueprint.WithComp(info); err != nil {
			panic(fmt.Sprintf("goke: view5 init failed: %v", err))
		}
	}

	// 1. Resolve Component Infos (Type -> ID)

	info1 := componentsRegistry.GetOrRegister(reflect.TypeFor[T1]())

	info2 := componentsRegistry.GetOrRegister(reflect.TypeFor[T2]())

	info3 := componentsRegistry.GetOrRegister(reflect.TypeFor[T3]())

	info4 := componentsRegistry.GetOrRegister(reflect.TypeFor[T4]())

	info5 := componentsRegistry.GetOrRegister(reflect.TypeFor[T5]())

	// 2. Add to Blueprint (Build Mask)

	mustAdd(info1)

	mustAdd(info2)

	mustAdd(info3)

	mustAdd(info4)

	mustAdd(info5)

	// 3. Apply dynamic options (Include/Exclude)
	for _, opt := range opts {
		if err := opt(blueprint); err != nil {
			panic(fmt.Sprintf("goke: view5 option failed: %v", err))
		}
	}

	// 4. Define Rigid Layout (Slice Literal - Zero Allocation Overhead)
	// This guarantees that T1 is at index 0, T2 at index 1, etc.
	layout := []core.ComponentInfo{
		info1, info2, info3, info4, info5,
	}

	view := core.NewView(blueprint, layout, registry)
	return &View5[T1, T2, T3, T4, T5]{View: view}
}

// All returns an iterator (iter.Seq2) that yields the unique Entity identifier
// and a tuple of pointers to its 5 components. This is designed for use
// in range loops, providing a clean, idiomatic Go way to process data while
// maintaining maximum cache efficiency.
//
// The iteration is performed archetype by archetype, ensuring that data is
// accessed contiguously in memory, which significantly reduces CPU cache misses.
//
// Example usage:
//
//	for head, tail := range view5.All() {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	    v5 := tail.V5
//
//	}
func (v *View5[T1, T2, T3, T4, T5]) All() iter.Seq2[
	struct {
		Entity core.Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct {
		V4 *T4
		V5 *T5
	},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct {
			V4 *T4
			V5 *T5
		},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))
		stride5 := unsafe.Sizeof(*new(T5))

		// Loop over matched archetypes - Value Copy is fast enough (stack allocation)
		for _, ma := range v.Baked {
			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// Accessing fields on stack-allocated 'ma' is blazing fast
			offsetEntity := ma.EntityChunkOffset
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]
			offset5 := ma.FieldsOffsets[4]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk (Pure Math)
				base := chunk.Ptr
				ptrEntity := unsafe.Add(base, offsetEntity)
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)
				ptr5 := unsafe.Add(base, offset5)

				// 5. Hot Loop (Death Loop)
				for count > 0 {
					// Construct Head
					head := struct {
						Entity core.Entity
						V1     *T1
						V2     *T2
						V3     *T3
					}{
						Entity: *(*core.Entity)(ptrEntity),
						V1:     (*T1)(ptr1),
						V2:     (*T2)(ptr2),
						V3:     (*T3)(ptr3),
					}

					// Construct Tail (if exists)

					tail := struct {
						V4 *T4
						V5 *T5
					}{
						V4: (*T4)(ptr4),
						V5: (*T5)(ptr5),
					}

					// Yield execution to the user
					if !yield(head, tail) {
						return
					}

					// 6. Pointer Arithmetic (Move to next row)
					ptrEntity = unsafe.Add(ptrEntity, core.EntitySize)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)
					ptr5 = unsafe.Add(ptr5, stride5)

					count--
				}
			}
		}
	}
}

// Filter returns an iterator (iter.Seq2) that yields only the entities
// specified in the selected slice, provided they match the View's archetype
// constraints. It is optimized for scenarios where a subset of entities
// is pre-determined (e.g., via spatial partitioning or sorted results)
// but requires high-speed access to their component data.
//
// The iterator performs an internal validation for each entity to ensure
// it still belongs to an archetype compatible with this View, preventing
// invalid memory access if the entity's composition has changed.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view5.Filter(selected) {
//	    entity := head.Entity
//	    v1 := head.V1
//
//
//	    v5 := tail.V5
//
//
//	}
func (v *View5[T1, T2, T3, T4, T5]) Filter(selected []Entity) iter.Seq2[
	struct {
		Entity Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct {
		V4 *T4
		V5 *T5
	},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct {
			V4 *T4
			V5 *T5
		},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Column descriptor cache
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column
		var col5 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Change Detection (Cache descriptors)
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache all column descriptors for this archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)
				col5 = currentArch.GetColumn(v.Layout[4].ID)

				lastArchID = link.ArchId
			}

			if currentArch == nil {
				continue
			}

			// 2. Resolve Chunk
			// Access the physical page using the index from the link
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			head := struct {
				Entity core.Entity
				V1     *T1
				V2     *T2
				V3     *T3
			}{
				Entity: e,
				V1:     (*T1)(col1.GetPointer(chunk, link.ChunkRow)),
				V2:     (*T2)(col2.GetPointer(chunk, link.ChunkRow)),
				V3:     (*T3)(col3.GetPointer(chunk, link.ChunkRow)),
			}

			// 4. Construct Result (Tail)

			tail := struct {
				V4 *T4
				V5 *T5
			}{
				V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow)),
				V5: (*T5)(col5.GetPointer(chunk, link.ChunkRow)),
			}

			if !yield(head, tail) {
				return
			}
		}
	}
}

// Values returns a performance-critical iterator (iter.Seq2) that yields only
// component pointers, grouped into anonymous head and tail structures.
// This method is specifically designed for high-throughput data processing
// where the Entity identifier is not required.
//
// By omitting the Entity ID, this method minimizes stack pressure and
// register usage, focusing purely on data-driven transformation.
//
// Example usage:
//
//	for head, tail := range view5.Values() {
//	    v1 := head.V1
//
//
//	    v5 := tail.V5
//
//	}
func (v *View5[T1, T2, T3, T4, T5]) Values() iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct{ V5 *T5 },
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct{ V5 *T5 },
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))
		stride5 := unsafe.Sizeof(*new(T5))

		// Loop over matched archetypes
		for _, ma := range v.Baked {

			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// We use the same lookup array as in All(), just skipping the Entity offset.
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]
			offset5 := ma.FieldsOffsets[4]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk
				// Pure math: ChunkBase + ComponentOffset
				base := chunk.Ptr
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)
				ptr5 := unsafe.Add(base, offset5)

				// 5. Hot Loop (Death Loop)
				for count > 0 {

					// Construct Head
					head := struct {
						V1 *T1
						V2 *T2
						V3 *T3
						V4 *T4
					}{V1: (*T1)(ptr1), V2: (*T2)(ptr2), V3: (*T3)(ptr3), V4: (*T4)(ptr4)}

					// Construct Tail

					tail := struct{ V5 *T5 }{V5: (*T5)(ptr5)}

					if !yield(head, tail) {
						return
					}

					// 6. Increment Pointers (Pointer Arithmetic)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)
					ptr5 = unsafe.Add(ptr5, stride5)

					count--
				}
			}
		}
	}
}

// FilterValues returns an iterator (iter.Seq2) that yields component pointers
// for a pre-selected subset of entities, skipping the Entity identifier.
// It is optimized for cases where the entity list is already known (e.g., from spatial partitioning).
//
// Like the Values method, it uses anonymous structures to ensure the Go compiler
// can perform aggressive register allocation by avoiding Entity ID overhead.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view5.FilterValues(selected) {
//	    v1 := head.V1
//
//
//	    v5 := tail.V5
//
//	}
func (v *View5[T1, T2, T3, T4, T5]) FilterValues(selected []core.Entity) iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct{ V5 *T5 },
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct{ V5 *T5 },
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Cache for column descriptors to avoid repeated map lookups
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column
		var col5 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Transition Detection
			// We only refresh column descriptors when the archetype changes.
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				// Verify if the archetype matches the view's mask requirements
				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache column accessors for this specific archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)
				col5 = currentArch.GetColumn(v.Layout[4].ID)

				lastArchID = link.ArchId
			}

			// If currentArch is nil, it means the current entity's archetype doesn't match the view
			if currentArch == nil {
				continue
			}

			// 2. Resolve Physical Chunk
			// Access the memory page (Chunk) using the index from the link store.
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			vhead := struct {
				V1 *T1
				V2 *T2
				V3 *T3
				V4 *T4
			}{V1: (*T1)(col1.GetPointer(chunk, link.ChunkRow)), V2: (*T2)(col2.GetPointer(chunk, link.ChunkRow)), V3: (*T3)(col3.GetPointer(chunk, link.ChunkRow)), V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow))}

			// 4. Construct Result (Tail)

			vtail := struct{ V5 *T5 }{V5: (*T5)(col5.GetPointer(chunk, link.ChunkRow))}

			if !yield(vhead, vtail) {
				return
			}
		}
	}
}

// --------------- View6 ---------------

// View6 provides a type-safe iterator and access layer for entities that
// possess exactly 6 specific stateful components. It acts as a specialized
// window into the ECS world, filtering archetypes that satisfy the required
// component mask and any additional constraints defined via BlueprintOptions.
//
// By leveraging pre-calculated component offsets, View6 enables
// O(1) access to component data during iteration, making it the primary
// tool for implementing high-performance systems and logic loops.
type View6[T1, T2, T3, T4, T5, T6 any] struct {
	*core.View
}

// NewView6 initializes a query for exactly 6 components.
// It panics if the component registration fails, if there are duplicate
// components, or if options (like Exclude) create a logical contradiction.
//
// This ensures that the View is valid and ready for high-performance
// iteration immediately after creation.
func NewView6[T1, T2, T3, T4, T5, T6 any](ecs *ECS, opts ...BlueprintOption) *View6[T1, T2, T3, T4, T5, T6] {
	registry := ecs.registry
	blueprint := core.NewBlueprint(registry)
	componentsRegistry := &registry.ComponentsRegistry

	// Helper: Validates that the required component can be part of the view.
	mustAdd := func(info core.ComponentInfo) {
		if err := blueprint.WithComp(info); err != nil {
			panic(fmt.Sprintf("goke: view6 init failed: %v", err))
		}
	}

	// 1. Resolve Component Infos (Type -> ID)

	info1 := componentsRegistry.GetOrRegister(reflect.TypeFor[T1]())

	info2 := componentsRegistry.GetOrRegister(reflect.TypeFor[T2]())

	info3 := componentsRegistry.GetOrRegister(reflect.TypeFor[T3]())

	info4 := componentsRegistry.GetOrRegister(reflect.TypeFor[T4]())

	info5 := componentsRegistry.GetOrRegister(reflect.TypeFor[T5]())

	info6 := componentsRegistry.GetOrRegister(reflect.TypeFor[T6]())

	// 2. Add to Blueprint (Build Mask)

	mustAdd(info1)

	mustAdd(info2)

	mustAdd(info3)

	mustAdd(info4)

	mustAdd(info5)

	mustAdd(info6)

	// 3. Apply dynamic options (Include/Exclude)
	for _, opt := range opts {
		if err := opt(blueprint); err != nil {
			panic(fmt.Sprintf("goke: view6 option failed: %v", err))
		}
	}

	// 4. Define Rigid Layout (Slice Literal - Zero Allocation Overhead)
	// This guarantees that T1 is at index 0, T2 at index 1, etc.
	layout := []core.ComponentInfo{
		info1, info2, info3, info4, info5, info6,
	}

	view := core.NewView(blueprint, layout, registry)
	return &View6[T1, T2, T3, T4, T5, T6]{View: view}
}

// All returns an iterator (iter.Seq2) that yields the unique Entity identifier
// and a tuple of pointers to its 6 components. This is designed for use
// in range loops, providing a clean, idiomatic Go way to process data while
// maintaining maximum cache efficiency.
//
// The iteration is performed archetype by archetype, ensuring that data is
// accessed contiguously in memory, which significantly reduces CPU cache misses.
//
// Example usage:
//
//	for head, tail := range view6.All() {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	    v6 := tail.V6
//
//	}
func (v *View6[T1, T2, T3, T4, T5, T6]) All() iter.Seq2[
	struct {
		Entity core.Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct {
		V4 *T4
		V5 *T5
		V6 *T6
	},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct {
			V4 *T4
			V5 *T5
			V6 *T6
		},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))
		stride5 := unsafe.Sizeof(*new(T5))
		stride6 := unsafe.Sizeof(*new(T6))

		// Loop over matched archetypes - Value Copy is fast enough (stack allocation)
		for _, ma := range v.Baked {
			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// Accessing fields on stack-allocated 'ma' is blazing fast
			offsetEntity := ma.EntityChunkOffset
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]
			offset5 := ma.FieldsOffsets[4]
			offset6 := ma.FieldsOffsets[5]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk (Pure Math)
				base := chunk.Ptr
				ptrEntity := unsafe.Add(base, offsetEntity)
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)
				ptr5 := unsafe.Add(base, offset5)
				ptr6 := unsafe.Add(base, offset6)

				// 5. Hot Loop (Death Loop)
				for count > 0 {
					// Construct Head
					head := struct {
						Entity core.Entity
						V1     *T1
						V2     *T2
						V3     *T3
					}{
						Entity: *(*core.Entity)(ptrEntity),
						V1:     (*T1)(ptr1),
						V2:     (*T2)(ptr2),
						V3:     (*T3)(ptr3),
					}

					// Construct Tail (if exists)

					tail := struct {
						V4 *T4
						V5 *T5
						V6 *T6
					}{
						V4: (*T4)(ptr4),
						V5: (*T5)(ptr5),
						V6: (*T6)(ptr6),
					}

					// Yield execution to the user
					if !yield(head, tail) {
						return
					}

					// 6. Pointer Arithmetic (Move to next row)
					ptrEntity = unsafe.Add(ptrEntity, core.EntitySize)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)
					ptr5 = unsafe.Add(ptr5, stride5)
					ptr6 = unsafe.Add(ptr6, stride6)

					count--
				}
			}
		}
	}
}

// Filter returns an iterator (iter.Seq2) that yields only the entities
// specified in the selected slice, provided they match the View's archetype
// constraints. It is optimized for scenarios where a subset of entities
// is pre-determined (e.g., via spatial partitioning or sorted results)
// but requires high-speed access to their component data.
//
// The iterator performs an internal validation for each entity to ensure
// it still belongs to an archetype compatible with this View, preventing
// invalid memory access if the entity's composition has changed.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view6.Filter(selected) {
//	    entity := head.Entity
//	    v1 := head.V1
//
//
//	    v6 := tail.V6
//
//
//	}
func (v *View6[T1, T2, T3, T4, T5, T6]) Filter(selected []Entity) iter.Seq2[
	struct {
		Entity Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct {
		V4 *T4
		V5 *T5
		V6 *T6
	},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct {
			V4 *T4
			V5 *T5
			V6 *T6
		},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Column descriptor cache
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column
		var col5 *core.Column
		var col6 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Change Detection (Cache descriptors)
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache all column descriptors for this archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)
				col5 = currentArch.GetColumn(v.Layout[4].ID)
				col6 = currentArch.GetColumn(v.Layout[5].ID)

				lastArchID = link.ArchId
			}

			if currentArch == nil {
				continue
			}

			// 2. Resolve Chunk
			// Access the physical page using the index from the link
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			head := struct {
				Entity core.Entity
				V1     *T1
				V2     *T2
				V3     *T3
			}{
				Entity: e,
				V1:     (*T1)(col1.GetPointer(chunk, link.ChunkRow)),
				V2:     (*T2)(col2.GetPointer(chunk, link.ChunkRow)),
				V3:     (*T3)(col3.GetPointer(chunk, link.ChunkRow)),
			}

			// 4. Construct Result (Tail)

			tail := struct {
				V4 *T4
				V5 *T5
				V6 *T6
			}{
				V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow)),
				V5: (*T5)(col5.GetPointer(chunk, link.ChunkRow)),
				V6: (*T6)(col6.GetPointer(chunk, link.ChunkRow)),
			}

			if !yield(head, tail) {
				return
			}
		}
	}
}

// Values returns a performance-critical iterator (iter.Seq2) that yields only
// component pointers, grouped into anonymous head and tail structures.
// This method is specifically designed for high-throughput data processing
// where the Entity identifier is not required.
//
// By omitting the Entity ID, this method minimizes stack pressure and
// register usage, focusing purely on data-driven transformation.
//
// Example usage:
//
//	for head, tail := range view6.Values() {
//	    v1 := head.V1
//
//
//	    v6 := tail.V6
//
//	}
func (v *View6[T1, T2, T3, T4, T5, T6]) Values() iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct {
		V5 *T5
		V6 *T6
	},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct {
			V5 *T5
			V6 *T6
		},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))
		stride5 := unsafe.Sizeof(*new(T5))
		stride6 := unsafe.Sizeof(*new(T6))

		// Loop over matched archetypes
		for _, ma := range v.Baked {

			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// We use the same lookup array as in All(), just skipping the Entity offset.
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]
			offset5 := ma.FieldsOffsets[4]
			offset6 := ma.FieldsOffsets[5]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk
				// Pure math: ChunkBase + ComponentOffset
				base := chunk.Ptr
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)
				ptr5 := unsafe.Add(base, offset5)
				ptr6 := unsafe.Add(base, offset6)

				// 5. Hot Loop (Death Loop)
				for count > 0 {

					// Construct Head
					head := struct {
						V1 *T1
						V2 *T2
						V3 *T3
						V4 *T4
					}{V1: (*T1)(ptr1), V2: (*T2)(ptr2), V3: (*T3)(ptr3), V4: (*T4)(ptr4)}

					// Construct Tail

					tail := struct {
						V5 *T5
						V6 *T6
					}{V5: (*T5)(ptr5), V6: (*T6)(ptr6)}

					if !yield(head, tail) {
						return
					}

					// 6. Increment Pointers (Pointer Arithmetic)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)
					ptr5 = unsafe.Add(ptr5, stride5)
					ptr6 = unsafe.Add(ptr6, stride6)

					count--
				}
			}
		}
	}
}

// FilterValues returns an iterator (iter.Seq2) that yields component pointers
// for a pre-selected subset of entities, skipping the Entity identifier.
// It is optimized for cases where the entity list is already known (e.g., from spatial partitioning).
//
// Like the Values method, it uses anonymous structures to ensure the Go compiler
// can perform aggressive register allocation by avoiding Entity ID overhead.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view6.FilterValues(selected) {
//	    v1 := head.V1
//
//
//	    v6 := tail.V6
//
//	}
func (v *View6[T1, T2, T3, T4, T5, T6]) FilterValues(selected []core.Entity) iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct {
		V5 *T5
		V6 *T6
	},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct {
			V5 *T5
			V6 *T6
		},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Cache for column descriptors to avoid repeated map lookups
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column
		var col5 *core.Column
		var col6 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Transition Detection
			// We only refresh column descriptors when the archetype changes.
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				// Verify if the archetype matches the view's mask requirements
				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache column accessors for this specific archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)
				col5 = currentArch.GetColumn(v.Layout[4].ID)
				col6 = currentArch.GetColumn(v.Layout[5].ID)

				lastArchID = link.ArchId
			}

			// If currentArch is nil, it means the current entity's archetype doesn't match the view
			if currentArch == nil {
				continue
			}

			// 2. Resolve Physical Chunk
			// Access the memory page (Chunk) using the index from the link store.
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			vhead := struct {
				V1 *T1
				V2 *T2
				V3 *T3
				V4 *T4
			}{V1: (*T1)(col1.GetPointer(chunk, link.ChunkRow)), V2: (*T2)(col2.GetPointer(chunk, link.ChunkRow)), V3: (*T3)(col3.GetPointer(chunk, link.ChunkRow)), V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow))}

			// 4. Construct Result (Tail)

			vtail := struct {
				V5 *T5
				V6 *T6
			}{V5: (*T5)(col5.GetPointer(chunk, link.ChunkRow)), V6: (*T6)(col6.GetPointer(chunk, link.ChunkRow))}

			if !yield(vhead, vtail) {
				return
			}
		}
	}
}

// --------------- View7 ---------------

// View7 provides a type-safe iterator and access layer for entities that
// possess exactly 7 specific stateful components. It acts as a specialized
// window into the ECS world, filtering archetypes that satisfy the required
// component mask and any additional constraints defined via BlueprintOptions.
//
// By leveraging pre-calculated component offsets, View7 enables
// O(1) access to component data during iteration, making it the primary
// tool for implementing high-performance systems and logic loops.
type View7[T1, T2, T3, T4, T5, T6, T7 any] struct {
	*core.View
}

// NewView7 initializes a query for exactly 7 components.
// It panics if the component registration fails, if there are duplicate
// components, or if options (like Exclude) create a logical contradiction.
//
// This ensures that the View is valid and ready for high-performance
// iteration immediately after creation.
func NewView7[T1, T2, T3, T4, T5, T6, T7 any](ecs *ECS, opts ...BlueprintOption) *View7[T1, T2, T3, T4, T5, T6, T7] {
	registry := ecs.registry
	blueprint := core.NewBlueprint(registry)
	componentsRegistry := &registry.ComponentsRegistry

	// Helper: Validates that the required component can be part of the view.
	mustAdd := func(info core.ComponentInfo) {
		if err := blueprint.WithComp(info); err != nil {
			panic(fmt.Sprintf("goke: view7 init failed: %v", err))
		}
	}

	// 1. Resolve Component Infos (Type -> ID)

	info1 := componentsRegistry.GetOrRegister(reflect.TypeFor[T1]())

	info2 := componentsRegistry.GetOrRegister(reflect.TypeFor[T2]())

	info3 := componentsRegistry.GetOrRegister(reflect.TypeFor[T3]())

	info4 := componentsRegistry.GetOrRegister(reflect.TypeFor[T4]())

	info5 := componentsRegistry.GetOrRegister(reflect.TypeFor[T5]())

	info6 := componentsRegistry.GetOrRegister(reflect.TypeFor[T6]())

	info7 := componentsRegistry.GetOrRegister(reflect.TypeFor[T7]())

	// 2. Add to Blueprint (Build Mask)

	mustAdd(info1)

	mustAdd(info2)

	mustAdd(info3)

	mustAdd(info4)

	mustAdd(info5)

	mustAdd(info6)

	mustAdd(info7)

	// 3. Apply dynamic options (Include/Exclude)
	for _, opt := range opts {
		if err := opt(blueprint); err != nil {
			panic(fmt.Sprintf("goke: view7 option failed: %v", err))
		}
	}

	// 4. Define Rigid Layout (Slice Literal - Zero Allocation Overhead)
	// This guarantees that T1 is at index 0, T2 at index 1, etc.
	layout := []core.ComponentInfo{
		info1, info2, info3, info4, info5, info6, info7,
	}

	view := core.NewView(blueprint, layout, registry)
	return &View7[T1, T2, T3, T4, T5, T6, T7]{View: view}
}

// All returns an iterator (iter.Seq2) that yields the unique Entity identifier
// and a tuple of pointers to its 7 components. This is designed for use
// in range loops, providing a clean, idiomatic Go way to process data while
// maintaining maximum cache efficiency.
//
// The iteration is performed archetype by archetype, ensuring that data is
// accessed contiguously in memory, which significantly reduces CPU cache misses.
//
// Example usage:
//
//	for head, tail := range view7.All() {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	    v7 := tail.V7
//
//	}
func (v *View7[T1, T2, T3, T4, T5, T6, T7]) All() iter.Seq2[
	struct {
		Entity core.Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct {
		V4 *T4
		V5 *T5
		V6 *T6
		V7 *T7
	},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct {
			V4 *T4
			V5 *T5
			V6 *T6
			V7 *T7
		},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))
		stride5 := unsafe.Sizeof(*new(T5))
		stride6 := unsafe.Sizeof(*new(T6))
		stride7 := unsafe.Sizeof(*new(T7))

		// Loop over matched archetypes - Value Copy is fast enough (stack allocation)
		for _, ma := range v.Baked {
			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// Accessing fields on stack-allocated 'ma' is blazing fast
			offsetEntity := ma.EntityChunkOffset
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]
			offset5 := ma.FieldsOffsets[4]
			offset6 := ma.FieldsOffsets[5]
			offset7 := ma.FieldsOffsets[6]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk (Pure Math)
				base := chunk.Ptr
				ptrEntity := unsafe.Add(base, offsetEntity)
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)
				ptr5 := unsafe.Add(base, offset5)
				ptr6 := unsafe.Add(base, offset6)
				ptr7 := unsafe.Add(base, offset7)

				// 5. Hot Loop (Death Loop)
				for count > 0 {
					// Construct Head
					head := struct {
						Entity core.Entity
						V1     *T1
						V2     *T2
						V3     *T3
					}{
						Entity: *(*core.Entity)(ptrEntity),
						V1:     (*T1)(ptr1),
						V2:     (*T2)(ptr2),
						V3:     (*T3)(ptr3),
					}

					// Construct Tail (if exists)

					tail := struct {
						V4 *T4
						V5 *T5
						V6 *T6
						V7 *T7
					}{
						V4: (*T4)(ptr4),
						V5: (*T5)(ptr5),
						V6: (*T6)(ptr6),
						V7: (*T7)(ptr7),
					}

					// Yield execution to the user
					if !yield(head, tail) {
						return
					}

					// 6. Pointer Arithmetic (Move to next row)
					ptrEntity = unsafe.Add(ptrEntity, core.EntitySize)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)
					ptr5 = unsafe.Add(ptr5, stride5)
					ptr6 = unsafe.Add(ptr6, stride6)
					ptr7 = unsafe.Add(ptr7, stride7)

					count--
				}
			}
		}
	}
}

// Filter returns an iterator (iter.Seq2) that yields only the entities
// specified in the selected slice, provided they match the View's archetype
// constraints. It is optimized for scenarios where a subset of entities
// is pre-determined (e.g., via spatial partitioning or sorted results)
// but requires high-speed access to their component data.
//
// The iterator performs an internal validation for each entity to ensure
// it still belongs to an archetype compatible with this View, preventing
// invalid memory access if the entity's composition has changed.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view7.Filter(selected) {
//	    entity := head.Entity
//	    v1 := head.V1
//
//
//	    v7 := tail.V7
//
//
//	}
func (v *View7[T1, T2, T3, T4, T5, T6, T7]) Filter(selected []Entity) iter.Seq2[
	struct {
		Entity Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct {
		V4 *T4
		V5 *T5
		V6 *T6
		V7 *T7
	},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct {
			V4 *T4
			V5 *T5
			V6 *T6
			V7 *T7
		},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Column descriptor cache
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column
		var col5 *core.Column
		var col6 *core.Column
		var col7 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Change Detection (Cache descriptors)
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache all column descriptors for this archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)
				col5 = currentArch.GetColumn(v.Layout[4].ID)
				col6 = currentArch.GetColumn(v.Layout[5].ID)
				col7 = currentArch.GetColumn(v.Layout[6].ID)

				lastArchID = link.ArchId
			}

			if currentArch == nil {
				continue
			}

			// 2. Resolve Chunk
			// Access the physical page using the index from the link
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			head := struct {
				Entity core.Entity
				V1     *T1
				V2     *T2
				V3     *T3
			}{
				Entity: e,
				V1:     (*T1)(col1.GetPointer(chunk, link.ChunkRow)),
				V2:     (*T2)(col2.GetPointer(chunk, link.ChunkRow)),
				V3:     (*T3)(col3.GetPointer(chunk, link.ChunkRow)),
			}

			// 4. Construct Result (Tail)

			tail := struct {
				V4 *T4
				V5 *T5
				V6 *T6
				V7 *T7
			}{
				V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow)),
				V5: (*T5)(col5.GetPointer(chunk, link.ChunkRow)),
				V6: (*T6)(col6.GetPointer(chunk, link.ChunkRow)),
				V7: (*T7)(col7.GetPointer(chunk, link.ChunkRow)),
			}

			if !yield(head, tail) {
				return
			}
		}
	}
}

// Values returns a performance-critical iterator (iter.Seq2) that yields only
// component pointers, grouped into anonymous head and tail structures.
// This method is specifically designed for high-throughput data processing
// where the Entity identifier is not required.
//
// By omitting the Entity ID, this method minimizes stack pressure and
// register usage, focusing purely on data-driven transformation.
//
// Example usage:
//
//	for head, tail := range view7.Values() {
//	    v1 := head.V1
//
//
//	    v7 := tail.V7
//
//	}
func (v *View7[T1, T2, T3, T4, T5, T6, T7]) Values() iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct {
		V5 *T5
		V6 *T6
		V7 *T7
	},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct {
			V5 *T5
			V6 *T6
			V7 *T7
		},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))
		stride5 := unsafe.Sizeof(*new(T5))
		stride6 := unsafe.Sizeof(*new(T6))
		stride7 := unsafe.Sizeof(*new(T7))

		// Loop over matched archetypes
		for _, ma := range v.Baked {

			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// We use the same lookup array as in All(), just skipping the Entity offset.
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]
			offset5 := ma.FieldsOffsets[4]
			offset6 := ma.FieldsOffsets[5]
			offset7 := ma.FieldsOffsets[6]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk
				// Pure math: ChunkBase + ComponentOffset
				base := chunk.Ptr
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)
				ptr5 := unsafe.Add(base, offset5)
				ptr6 := unsafe.Add(base, offset6)
				ptr7 := unsafe.Add(base, offset7)

				// 5. Hot Loop (Death Loop)
				for count > 0 {

					// Construct Head
					head := struct {
						V1 *T1
						V2 *T2
						V3 *T3
						V4 *T4
					}{V1: (*T1)(ptr1), V2: (*T2)(ptr2), V3: (*T3)(ptr3), V4: (*T4)(ptr4)}

					// Construct Tail

					tail := struct {
						V5 *T5
						V6 *T6
						V7 *T7
					}{V5: (*T5)(ptr5), V6: (*T6)(ptr6), V7: (*T7)(ptr7)}

					if !yield(head, tail) {
						return
					}

					// 6. Increment Pointers (Pointer Arithmetic)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)
					ptr5 = unsafe.Add(ptr5, stride5)
					ptr6 = unsafe.Add(ptr6, stride6)
					ptr7 = unsafe.Add(ptr7, stride7)

					count--
				}
			}
		}
	}
}

// FilterValues returns an iterator (iter.Seq2) that yields component pointers
// for a pre-selected subset of entities, skipping the Entity identifier.
// It is optimized for cases where the entity list is already known (e.g., from spatial partitioning).
//
// Like the Values method, it uses anonymous structures to ensure the Go compiler
// can perform aggressive register allocation by avoiding Entity ID overhead.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view7.FilterValues(selected) {
//	    v1 := head.V1
//
//
//	    v7 := tail.V7
//
//	}
func (v *View7[T1, T2, T3, T4, T5, T6, T7]) FilterValues(selected []core.Entity) iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct {
		V5 *T5
		V6 *T6
		V7 *T7
	},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct {
			V5 *T5
			V6 *T6
			V7 *T7
		},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Cache for column descriptors to avoid repeated map lookups
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column
		var col5 *core.Column
		var col6 *core.Column
		var col7 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Transition Detection
			// We only refresh column descriptors when the archetype changes.
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				// Verify if the archetype matches the view's mask requirements
				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache column accessors for this specific archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)
				col5 = currentArch.GetColumn(v.Layout[4].ID)
				col6 = currentArch.GetColumn(v.Layout[5].ID)
				col7 = currentArch.GetColumn(v.Layout[6].ID)

				lastArchID = link.ArchId
			}

			// If currentArch is nil, it means the current entity's archetype doesn't match the view
			if currentArch == nil {
				continue
			}

			// 2. Resolve Physical Chunk
			// Access the memory page (Chunk) using the index from the link store.
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			vhead := struct {
				V1 *T1
				V2 *T2
				V3 *T3
				V4 *T4
			}{V1: (*T1)(col1.GetPointer(chunk, link.ChunkRow)), V2: (*T2)(col2.GetPointer(chunk, link.ChunkRow)), V3: (*T3)(col3.GetPointer(chunk, link.ChunkRow)), V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow))}

			// 4. Construct Result (Tail)

			vtail := struct {
				V5 *T5
				V6 *T6
				V7 *T7
			}{V5: (*T5)(col5.GetPointer(chunk, link.ChunkRow)), V6: (*T6)(col6.GetPointer(chunk, link.ChunkRow)), V7: (*T7)(col7.GetPointer(chunk, link.ChunkRow))}

			if !yield(vhead, vtail) {
				return
			}
		}
	}
}

// --------------- View8 ---------------

// View8 provides a type-safe iterator and access layer for entities that
// possess exactly 8 specific stateful components. It acts as a specialized
// window into the ECS world, filtering archetypes that satisfy the required
// component mask and any additional constraints defined via BlueprintOptions.
//
// By leveraging pre-calculated component offsets, View8 enables
// O(1) access to component data during iteration, making it the primary
// tool for implementing high-performance systems and logic loops.
type View8[T1, T2, T3, T4, T5, T6, T7, T8 any] struct {
	*core.View
}

// NewView8 initializes a query for exactly 8 components.
// It panics if the component registration fails, if there are duplicate
// components, or if options (like Exclude) create a logical contradiction.
//
// This ensures that the View is valid and ready for high-performance
// iteration immediately after creation.
func NewView8[T1, T2, T3, T4, T5, T6, T7, T8 any](ecs *ECS, opts ...BlueprintOption) *View8[T1, T2, T3, T4, T5, T6, T7, T8] {
	registry := ecs.registry
	blueprint := core.NewBlueprint(registry)
	componentsRegistry := &registry.ComponentsRegistry

	// Helper: Validates that the required component can be part of the view.
	mustAdd := func(info core.ComponentInfo) {
		if err := blueprint.WithComp(info); err != nil {
			panic(fmt.Sprintf("goke: view8 init failed: %v", err))
		}
	}

	// 1. Resolve Component Infos (Type -> ID)

	info1 := componentsRegistry.GetOrRegister(reflect.TypeFor[T1]())

	info2 := componentsRegistry.GetOrRegister(reflect.TypeFor[T2]())

	info3 := componentsRegistry.GetOrRegister(reflect.TypeFor[T3]())

	info4 := componentsRegistry.GetOrRegister(reflect.TypeFor[T4]())

	info5 := componentsRegistry.GetOrRegister(reflect.TypeFor[T5]())

	info6 := componentsRegistry.GetOrRegister(reflect.TypeFor[T6]())

	info7 := componentsRegistry.GetOrRegister(reflect.TypeFor[T7]())

	info8 := componentsRegistry.GetOrRegister(reflect.TypeFor[T8]())

	// 2. Add to Blueprint (Build Mask)

	mustAdd(info1)

	mustAdd(info2)

	mustAdd(info3)

	mustAdd(info4)

	mustAdd(info5)

	mustAdd(info6)

	mustAdd(info7)

	mustAdd(info8)

	// 3. Apply dynamic options (Include/Exclude)
	for _, opt := range opts {
		if err := opt(blueprint); err != nil {
			panic(fmt.Sprintf("goke: view8 option failed: %v", err))
		}
	}

	// 4. Define Rigid Layout (Slice Literal - Zero Allocation Overhead)
	// This guarantees that T1 is at index 0, T2 at index 1, etc.
	layout := []core.ComponentInfo{
		info1, info2, info3, info4, info5, info6, info7, info8,
	}

	view := core.NewView(blueprint, layout, registry)
	return &View8[T1, T2, T3, T4, T5, T6, T7, T8]{View: view}
}

// All returns an iterator (iter.Seq2) that yields the unique Entity identifier
// and a tuple of pointers to its 8 components. This is designed for use
// in range loops, providing a clean, idiomatic Go way to process data while
// maintaining maximum cache efficiency.
//
// The iteration is performed archetype by archetype, ensuring that data is
// accessed contiguously in memory, which significantly reduces CPU cache misses.
//
// Example usage:
//
//	for head, tail := range view8.All() {
//	    entity := head.Entity
//	    v1 := head.V1
//
//	    v8 := tail.V8
//
//	}
func (v *View8[T1, T2, T3, T4, T5, T6, T7, T8]) All() iter.Seq2[
	struct {
		Entity core.Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct {
		V4 *T4
		V5 *T5
		V6 *T6
		V7 *T7
		V8 *T8
	},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct {
			V4 *T4
			V5 *T5
			V6 *T6
			V7 *T7
			V8 *T8
		},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))
		stride5 := unsafe.Sizeof(*new(T5))
		stride6 := unsafe.Sizeof(*new(T6))
		stride7 := unsafe.Sizeof(*new(T7))
		stride8 := unsafe.Sizeof(*new(T8))

		// Loop over matched archetypes - Value Copy is fast enough (stack allocation)
		for _, ma := range v.Baked {
			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// Accessing fields on stack-allocated 'ma' is blazing fast
			offsetEntity := ma.EntityChunkOffset
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]
			offset5 := ma.FieldsOffsets[4]
			offset6 := ma.FieldsOffsets[5]
			offset7 := ma.FieldsOffsets[6]
			offset8 := ma.FieldsOffsets[7]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk (Pure Math)
				base := chunk.Ptr
				ptrEntity := unsafe.Add(base, offsetEntity)
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)
				ptr5 := unsafe.Add(base, offset5)
				ptr6 := unsafe.Add(base, offset6)
				ptr7 := unsafe.Add(base, offset7)
				ptr8 := unsafe.Add(base, offset8)

				// 5. Hot Loop (Death Loop)
				for count > 0 {
					// Construct Head
					head := struct {
						Entity core.Entity
						V1     *T1
						V2     *T2
						V3     *T3
					}{
						Entity: *(*core.Entity)(ptrEntity),
						V1:     (*T1)(ptr1),
						V2:     (*T2)(ptr2),
						V3:     (*T3)(ptr3),
					}

					// Construct Tail (if exists)

					tail := struct {
						V4 *T4
						V5 *T5
						V6 *T6
						V7 *T7
						V8 *T8
					}{
						V4: (*T4)(ptr4),
						V5: (*T5)(ptr5),
						V6: (*T6)(ptr6),
						V7: (*T7)(ptr7),
						V8: (*T8)(ptr8),
					}

					// Yield execution to the user
					if !yield(head, tail) {
						return
					}

					// 6. Pointer Arithmetic (Move to next row)
					ptrEntity = unsafe.Add(ptrEntity, core.EntitySize)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)
					ptr5 = unsafe.Add(ptr5, stride5)
					ptr6 = unsafe.Add(ptr6, stride6)
					ptr7 = unsafe.Add(ptr7, stride7)
					ptr8 = unsafe.Add(ptr8, stride8)

					count--
				}
			}
		}
	}
}

// Filter returns an iterator (iter.Seq2) that yields only the entities
// specified in the selected slice, provided they match the View's archetype
// constraints. It is optimized for scenarios where a subset of entities
// is pre-determined (e.g., via spatial partitioning or sorted results)
// but requires high-speed access to their component data.
//
// The iterator performs an internal validation for each entity to ensure
// it still belongs to an archetype compatible with this View, preventing
// invalid memory access if the entity's composition has changed.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view8.Filter(selected) {
//	    entity := head.Entity
//	    v1 := head.V1
//
//
//	    v8 := tail.V8
//
//
//	}
func (v *View8[T1, T2, T3, T4, T5, T6, T7, T8]) Filter(selected []Entity) iter.Seq2[
	struct {
		Entity Entity
		V1     *T1
		V2     *T2
		V3     *T3
	},
	struct {
		V4 *T4
		V5 *T5
		V6 *T6
		V7 *T7
		V8 *T8
	},
] {
	return func(yield func(
		struct {
			Entity core.Entity
			V1     *T1
			V2     *T2
			V3     *T3
		},
		struct {
			V4 *T4
			V5 *T5
			V6 *T6
			V7 *T7
			V8 *T8
		},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Column descriptor cache
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column
		var col5 *core.Column
		var col6 *core.Column
		var col7 *core.Column
		var col8 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Change Detection (Cache descriptors)
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache all column descriptors for this archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)
				col5 = currentArch.GetColumn(v.Layout[4].ID)
				col6 = currentArch.GetColumn(v.Layout[5].ID)
				col7 = currentArch.GetColumn(v.Layout[6].ID)
				col8 = currentArch.GetColumn(v.Layout[7].ID)

				lastArchID = link.ArchId
			}

			if currentArch == nil {
				continue
			}

			// 2. Resolve Chunk
			// Access the physical page using the index from the link
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			head := struct {
				Entity core.Entity
				V1     *T1
				V2     *T2
				V3     *T3
			}{
				Entity: e,
				V1:     (*T1)(col1.GetPointer(chunk, link.ChunkRow)),
				V2:     (*T2)(col2.GetPointer(chunk, link.ChunkRow)),
				V3:     (*T3)(col3.GetPointer(chunk, link.ChunkRow)),
			}

			// 4. Construct Result (Tail)

			tail := struct {
				V4 *T4
				V5 *T5
				V6 *T6
				V7 *T7
				V8 *T8
			}{
				V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow)),
				V5: (*T5)(col5.GetPointer(chunk, link.ChunkRow)),
				V6: (*T6)(col6.GetPointer(chunk, link.ChunkRow)),
				V7: (*T7)(col7.GetPointer(chunk, link.ChunkRow)),
				V8: (*T8)(col8.GetPointer(chunk, link.ChunkRow)),
			}

			if !yield(head, tail) {
				return
			}
		}
	}
}

// Values returns a performance-critical iterator (iter.Seq2) that yields only
// component pointers, grouped into anonymous head and tail structures.
// This method is specifically designed for high-throughput data processing
// where the Entity identifier is not required.
//
// By omitting the Entity ID, this method minimizes stack pressure and
// register usage, focusing purely on data-driven transformation.
//
// Example usage:
//
//	for head, tail := range view8.Values() {
//	    v1 := head.V1
//
//
//	    v8 := tail.V8
//
//	}
func (v *View8[T1, T2, T3, T4, T5, T6, T7, T8]) Values() iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct {
		V5 *T5
		V6 *T6
		V7 *T7
		V8 *T8
	},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct {
			V5 *T5
			V6 *T6
			V7 *T7
			V8 *T8
		},
	) bool) {
		// 1. Pre-calculate Strides (Invariant)
		stride1 := unsafe.Sizeof(*new(T1))
		stride2 := unsafe.Sizeof(*new(T2))
		stride3 := unsafe.Sizeof(*new(T3))
		stride4 := unsafe.Sizeof(*new(T4))
		stride5 := unsafe.Sizeof(*new(T5))
		stride6 := unsafe.Sizeof(*new(T6))
		stride7 := unsafe.Sizeof(*new(T7))
		stride8 := unsafe.Sizeof(*new(T8))

		// Loop over matched archetypes
		for _, ma := range v.Baked {

			// 2. Load Offsets from Cache (L1 Cache Friendly)
			// We use the same lookup array as in All(), just skipping the Entity offset.
			offset1 := ma.FieldsOffsets[0]
			offset2 := ma.FieldsOffsets[1]
			offset3 := ma.FieldsOffsets[2]
			offset4 := ma.FieldsOffsets[3]
			offset5 := ma.FieldsOffsets[4]
			offset6 := ma.FieldsOffsets[5]
			offset7 := ma.FieldsOffsets[6]
			offset8 := ma.FieldsOffsets[7]

			// 3. Loop over Physical Memory Pages (CHUNKS)
			for _, chunk := range ma.Arch.Memory.Pages {
				count := chunk.Len
				if count == 0 {
					continue
				}

				// 4. Resolve Base Pointers for this Chunk
				// Pure math: ChunkBase + ComponentOffset
				base := chunk.Ptr
				ptr1 := unsafe.Add(base, offset1)
				ptr2 := unsafe.Add(base, offset2)
				ptr3 := unsafe.Add(base, offset3)
				ptr4 := unsafe.Add(base, offset4)
				ptr5 := unsafe.Add(base, offset5)
				ptr6 := unsafe.Add(base, offset6)
				ptr7 := unsafe.Add(base, offset7)
				ptr8 := unsafe.Add(base, offset8)

				// 5. Hot Loop (Death Loop)
				for count > 0 {

					// Construct Head
					head := struct {
						V1 *T1
						V2 *T2
						V3 *T3
						V4 *T4
					}{V1: (*T1)(ptr1), V2: (*T2)(ptr2), V3: (*T3)(ptr3), V4: (*T4)(ptr4)}

					// Construct Tail

					tail := struct {
						V5 *T5
						V6 *T6
						V7 *T7
						V8 *T8
					}{V5: (*T5)(ptr5), V6: (*T6)(ptr6), V7: (*T7)(ptr7), V8: (*T8)(ptr8)}

					if !yield(head, tail) {
						return
					}

					// 6. Increment Pointers (Pointer Arithmetic)
					ptr1 = unsafe.Add(ptr1, stride1)
					ptr2 = unsafe.Add(ptr2, stride2)
					ptr3 = unsafe.Add(ptr3, stride3)
					ptr4 = unsafe.Add(ptr4, stride4)
					ptr5 = unsafe.Add(ptr5, stride5)
					ptr6 = unsafe.Add(ptr6, stride6)
					ptr7 = unsafe.Add(ptr7, stride7)
					ptr8 = unsafe.Add(ptr8, stride8)

					count--
				}
			}
		}
	}
}

// FilterValues returns an iterator (iter.Seq2) that yields component pointers
// for a pre-selected subset of entities, skipping the Entity identifier.
// It is optimized for cases where the entity list is already known (e.g., from spatial partitioning).
//
// Like the Values method, it uses anonymous structures to ensure the Go compiler
// can perform aggressive register allocation by avoiding Entity ID overhead.
//
// Example usage:
//
//	selected := []Entity{e1, e5, e10}
//	for head, tail := range view8.FilterValues(selected) {
//	    v1 := head.V1
//
//
//	    v8 := tail.V8
//
//	}
func (v *View8[T1, T2, T3, T4, T5, T6, T7, T8]) FilterValues(selected []core.Entity) iter.Seq2[
	struct {
		V1 *T1
		V2 *T2
		V3 *T3
		V4 *T4
	},
	struct {
		V5 *T5
		V6 *T6
		V7 *T7
		V8 *T8
	},
] {
	return func(yield func(
		struct {
			V1 *T1
			V2 *T2
			V3 *T3
			V4 *T4
		},
		struct {
			V5 *T5
			V6 *T6
			V7 *T7
			V8 *T8
		},
	) bool) {
		var lastArchID core.ArchetypeId = core.NullArchetypeId
		var currentArch *core.Archetype

		// Cache for column descriptors to avoid repeated map lookups
		var col1 *core.Column
		var col2 *core.Column
		var col3 *core.Column
		var col4 *core.Column
		var col5 *core.Column
		var col6 *core.Column
		var col7 *core.Column
		var col8 *core.Column

		registry := v.Reg.ArchetypeRegistry

		for _, e := range selected {
			link, ok := registry.EntityLinkStore.Get(e)
			if !ok {
				continue
			}

			// 1. Archetype Transition Detection
			// We only refresh column descriptors when the archetype changes.
			if link.ArchId != lastArchID {
				currentArch = &registry.Archetypes[link.ArchId]

				// Verify if the archetype matches the view's mask requirements
				if !v.View.Matches(currentArch.Mask) {
					lastArchID = core.NullArchetypeId
					currentArch = nil
					continue
				}

				// Cache column accessors for this specific archetype
				col1 = currentArch.GetColumn(v.Layout[0].ID)
				col2 = currentArch.GetColumn(v.Layout[1].ID)
				col3 = currentArch.GetColumn(v.Layout[2].ID)
				col4 = currentArch.GetColumn(v.Layout[3].ID)
				col5 = currentArch.GetColumn(v.Layout[4].ID)
				col6 = currentArch.GetColumn(v.Layout[5].ID)
				col7 = currentArch.GetColumn(v.Layout[6].ID)
				col8 = currentArch.GetColumn(v.Layout[7].ID)

				lastArchID = link.ArchId
			}

			// If currentArch is nil, it means the current entity's archetype doesn't match the view
			if currentArch == nil {
				continue
			}

			// 2. Resolve Physical Chunk
			// Access the memory page (Chunk) using the index from the link store.
			chunk := currentArch.Memory.Pages[link.ChunkIdx]

			// 3. Construct Result (Head)
			vhead := struct {
				V1 *T1
				V2 *T2
				V3 *T3
				V4 *T4
			}{V1: (*T1)(col1.GetPointer(chunk, link.ChunkRow)), V2: (*T2)(col2.GetPointer(chunk, link.ChunkRow)), V3: (*T3)(col3.GetPointer(chunk, link.ChunkRow)), V4: (*T4)(col4.GetPointer(chunk, link.ChunkRow))}

			// 4. Construct Result (Tail)

			vtail := struct {
				V5 *T5
				V6 *T6
				V7 *T7
				V8 *T8
			}{V5: (*T5)(col5.GetPointer(chunk, link.ChunkRow)), V6: (*T6)(col6.GetPointer(chunk, link.ChunkRow)), V7: (*T7)(col7.GetPointer(chunk, link.ChunkRow)), V8: (*T8)(col8.GetPointer(chunk, link.ChunkRow))}

			if !yield(vhead, vtail) {
				return
			}
		}
	}
}
